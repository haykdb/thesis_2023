{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c9a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b7801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the image data\n",
    "data_dir = r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\Dataset\\Pics_20_5\\Train\"\n",
    "\n",
    "# Define the target image size and batch size\n",
    "target_size = (60, 64)\n",
    "batch_size = 128\n",
    "\n",
    "# Define the class names\n",
    "class_names = os.listdir(data_dir)\n",
    "\n",
    "# Define the train-test split ratio\n",
    "split_ratio = 0.5\n",
    "\n",
    "# Load the image data and labels\n",
    "data = []\n",
    "labels = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        img = tf.keras.preprocessing.image.load_img(os.path.join(class_dir, filename), color_mode = 'grayscale', target_size=target_size)\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img, data_format = 'channels_last')\n",
    "#         img = tf.keras.applications.resnet50.preprocess_input(img)\n",
    "        data.append(img)\n",
    "        labels.append(i)\n",
    "\n",
    "# Convert the data and labels to numpy arrays\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Define the total number of samples and the number of samples per class\n",
    "num_samples = len(labels)\n",
    "num_samples_per_class = num_samples // len(class_names)\n",
    "print(num_samples)\n",
    "# Shuffle the data and labels\n",
    "shuffle_idx = np.random.permutation(num_samples)\n",
    "data = data[shuffle_idx]\n",
    "labels = labels[shuffle_idx]\n",
    "\n",
    "# Split the data and labels into train and test sets with equal proportions for each class\n",
    "train_data = []\n",
    "train_labels = []\n",
    "test_data = []\n",
    "test_labels = []\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_indices = np.where(labels == i)[0]\n",
    "    num_train_samples = int(split_ratio * num_samples_per_class)\n",
    "    num_test_samples = num_samples_per_class - num_train_samples\n",
    "    train_indices = class_indices[:num_train_samples]\n",
    "    test_indices = class_indices[num_train_samples:num_samples_per_class]\n",
    "    train_data.append(data[train_indices])\n",
    "    train_labels.append(labels[train_indices])\n",
    "    test_data.append(data[test_indices])\n",
    "    test_labels.append(labels[test_indices])\n",
    "\n",
    "train_data = np.concatenate(train_data)\n",
    "train_labels = np.concatenate(train_labels)\n",
    "test_data = np.concatenate(test_data)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "\n",
    "# Create TensorFlow datasets for the train and test sets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_labels)).batch(batch_size)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_labels)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c574ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = tf.keras.preprocessing.image.load_img(r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\Dataset\\Pics_20_5\\Train\\class_a\\a_image_0.jpg\", color_mode = 'grayscale')\n",
    "img = tf.keras.preprocessing.image.img_to_array(img, data_format = 'channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0cf68f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.utils' has no attribute 'array_to_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_img\u001b[49m(\n\u001b[0;32m      2\u001b[0m     img, data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m      3\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.utils' has no attribute 'array_to_img'"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.array_to_img(\n",
    "    img, data_format=None, scale=True, dtype=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc9087aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.keras.utils' has no attribute 'array_to_img'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m help(\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_img\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.keras.utils' has no attribute 'array_to_img'"
     ]
    }
   ],
   "source": [
    "help(tf.keras.utils.array_to_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a77de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14570 images belonging to 2 classes.\n",
      "Found 3671 images belonging to 2 classes.\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 53ms/step - loss: 0.6988 - accuracy: 0.4919 - val_loss: 0.6931 - val_accuracy: 0.5050\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.6927 - accuracy: 0.5283 - val_loss: 0.6975 - val_accuracy: 0.5038\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 4s 57ms/step - loss: 0.6934 - accuracy: 0.5088 - val_loss: 0.6930 - val_accuracy: 0.5500\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.6916 - accuracy: 0.5246 - val_loss: 0.6932 - val_accuracy: 0.5088\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6924 - accuracy: 0.5131 - val_loss: 0.6942 - val_accuracy: 0.5038\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6893 - accuracy: 0.5454 - val_loss: 0.6950 - val_accuracy: 0.5063\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6849 - accuracy: 0.5635 - val_loss: 0.6953 - val_accuracy: 0.4888\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.6865 - accuracy: 0.5459 - val_loss: 0.7009 - val_accuracy: 0.4850\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6808 - accuracy: 0.5615 - val_loss: 0.7031 - val_accuracy: 0.4825\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.6854 - accuracy: 0.5697 - val_loss: 0.6999 - val_accuracy: 0.5213\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.6826 - accuracy: 0.5682 - val_loss: 0.7049 - val_accuracy: 0.4863\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 5s 77ms/step - loss: 0.6838 - accuracy: 0.5576 - val_loss: 0.7073 - val_accuracy: 0.4650\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 5s 78ms/step - loss: 0.6816 - accuracy: 0.5788 - val_loss: 0.7019 - val_accuracy: 0.5138\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 4s 61ms/step - loss: 0.6803 - accuracy: 0.5692 - val_loss: 0.7153 - val_accuracy: 0.5100\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6701 - accuracy: 0.5959 - val_loss: 0.7158 - val_accuracy: 0.4888\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 3s 50ms/step - loss: 0.6774 - accuracy: 0.5593 - val_loss: 0.7366 - val_accuracy: 0.4525\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 4s 64ms/step - loss: 0.6754 - accuracy: 0.5685 - val_loss: 0.7453 - val_accuracy: 0.4888\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6719 - accuracy: 0.5820 - val_loss: 0.7223 - val_accuracy: 0.4725\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6686 - accuracy: 0.5900 - val_loss: 0.7528 - val_accuracy: 0.4775\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.6690 - accuracy: 0.5881 - val_loss: 0.7705 - val_accuracy: 0.4500\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6633 - accuracy: 0.5827 - val_loss: 0.7344 - val_accuracy: 0.4650\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.6683 - accuracy: 0.5785 - val_loss: 0.7451 - val_accuracy: 0.4950\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6704 - accuracy: 0.5733 - val_loss: 0.7467 - val_accuracy: 0.4938\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.6586 - accuracy: 0.6031 - val_loss: 0.7859 - val_accuracy: 0.4688\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 0.6597 - accuracy: 0.6064 - val_loss: 0.7737 - val_accuracy: 0.4925\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 5s 79ms/step - loss: 0.6667 - accuracy: 0.5867 - val_loss: 0.7853 - val_accuracy: 0.5038\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.6673 - accuracy: 0.5891 - val_loss: 0.8087 - val_accuracy: 0.4700\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 3s 54ms/step - loss: 0.6644 - accuracy: 0.5907 - val_loss: 0.8022 - val_accuracy: 0.4988\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6509 - accuracy: 0.6129 - val_loss: 0.7956 - val_accuracy: 0.4762\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 4s 63ms/step - loss: 0.6490 - accuracy: 0.6018 - val_loss: 0.7817 - val_accuracy: 0.5025\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6507 - accuracy: 0.6257 - val_loss: 0.7930 - val_accuracy: 0.4875\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6550 - accuracy: 0.6092 - val_loss: 0.7929 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 0.6434 - accuracy: 0.6215 - val_loss: 0.7898 - val_accuracy: 0.5025\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.6373 - accuracy: 0.6492 - val_loss: 0.7940 - val_accuracy: 0.5050\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6455 - accuracy: 0.6255 - val_loss: 0.8429 - val_accuracy: 0.5025\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6386 - accuracy: 0.6323 - val_loss: 0.8366 - val_accuracy: 0.5050\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6117 - accuracy: 0.6715 - val_loss: 0.8314 - val_accuracy: 0.4938\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.6347 - accuracy: 0.6293 - val_loss: 0.8651 - val_accuracy: 0.4950\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 5s 78ms/step - loss: 0.6280 - accuracy: 0.6421 - val_loss: 0.8250 - val_accuracy: 0.4863\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 5s 78ms/step - loss: 0.6155 - accuracy: 0.6748 - val_loss: 0.8746 - val_accuracy: 0.5088\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.6102 - accuracy: 0.6504 - val_loss: 0.8663 - val_accuracy: 0.4950\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.6214 - accuracy: 0.6450 - val_loss: 0.9507 - val_accuracy: 0.4825\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.6158 - accuracy: 0.6518 - val_loss: 0.8850 - val_accuracy: 0.4825\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.5905 - accuracy: 0.6761 - val_loss: 0.9573 - val_accuracy: 0.4938\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.5826 - accuracy: 0.6845 - val_loss: 0.9447 - val_accuracy: 0.4875\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.6046 - accuracy: 0.6627 - val_loss: 0.9048 - val_accuracy: 0.4675\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.5852 - accuracy: 0.6904 - val_loss: 0.9858 - val_accuracy: 0.4737\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.6077 - accuracy: 0.6648 - val_loss: 0.9957 - val_accuracy: 0.4487\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 0.6025 - accuracy: 0.6813 - val_loss: 0.9568 - val_accuracy: 0.4725\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.5932 - accuracy: 0.6818 - val_loss: 1.0087 - val_accuracy: 0.4425\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 0.5611 - accuracy: 0.7061 - val_loss: 0.9778 - val_accuracy: 0.4500\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 5s 73ms/step - loss: 0.5374 - accuracy: 0.7094 - val_loss: 0.9800 - val_accuracy: 0.4938\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 5s 80ms/step - loss: 0.5645 - accuracy: 0.6996 - val_loss: 0.9505 - val_accuracy: 0.4688\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 5s 74ms/step - loss: 0.5562 - accuracy: 0.7098 - val_loss: 0.9733 - val_accuracy: 0.4787\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5458 - accuracy: 0.7252 - val_loss: 0.9581 - val_accuracy: 0.4825\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.5630 - accuracy: 0.7078 - val_loss: 1.0269 - val_accuracy: 0.4762\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 4s 59ms/step - loss: 0.5437 - accuracy: 0.7355 - val_loss: 1.1543 - val_accuracy: 0.4487\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.5309 - accuracy: 0.7352 - val_loss: 0.9499 - val_accuracy: 0.4850\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.5115 - accuracy: 0.7483 - val_loss: 1.1559 - val_accuracy: 0.4700\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.5502 - accuracy: 0.7167 - val_loss: 1.1166 - val_accuracy: 0.4762\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.5278 - accuracy: 0.7376 - val_loss: 1.0728 - val_accuracy: 0.4600\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.4950 - accuracy: 0.7633 - val_loss: 1.0125 - val_accuracy: 0.4663\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.4998 - accuracy: 0.7490 - val_loss: 0.9881 - val_accuracy: 0.4913\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 4s 70ms/step - loss: 0.5023 - accuracy: 0.7485 - val_loss: 1.1071 - val_accuracy: 0.4787\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 4s 71ms/step - loss: 0.5188 - accuracy: 0.7522 - val_loss: 0.9927 - val_accuracy: 0.4888\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 5s 80ms/step - loss: 0.4970 - accuracy: 0.7503 - val_loss: 1.0482 - val_accuracy: 0.4875\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 5s 82ms/step - loss: 0.5208 - accuracy: 0.7496 - val_loss: 1.0064 - val_accuracy: 0.5188\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4867 - accuracy: 0.7539 - val_loss: 1.1130 - val_accuracy: 0.5025\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 3s 52ms/step - loss: 0.5050 - accuracy: 0.7495 - val_loss: 1.0172 - val_accuracy: 0.5038\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 3s 51ms/step - loss: 0.4867 - accuracy: 0.7439 - val_loss: 1.0105 - val_accuracy: 0.4925\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.5069 - accuracy: 0.7357 - val_loss: 1.0788 - val_accuracy: 0.4875\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 4s 65ms/step - loss: 0.4577 - accuracy: 0.7770 - val_loss: 1.0723 - val_accuracy: 0.4812\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.4703 - accuracy: 0.7563 - val_loss: 1.1502 - val_accuracy: 0.4700\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.5033 - accuracy: 0.7745 - val_loss: 1.0324 - val_accuracy: 0.4800\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 4s 66ms/step - loss: 0.4871 - accuracy: 0.7738 - val_loss: 1.2544 - val_accuracy: 0.4787\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.4485 - accuracy: 0.7932 - val_loss: 1.0969 - val_accuracy: 0.4850\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 4s 69ms/step - loss: 0.4855 - accuracy: 0.7644 - val_loss: 1.1521 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 4s 67ms/step - loss: 0.4442 - accuracy: 0.7745 - val_loss: 1.1543 - val_accuracy: 0.4712\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 5s 77ms/step - loss: 0.4686 - accuracy: 0.7761 - val_loss: 1.1392 - val_accuracy: 0.4588\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 5s 78ms/step - loss: 0.4435 - accuracy: 0.8014 - val_loss: 1.1742 - val_accuracy: 0.4825\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 4s 68ms/step - loss: 0.4164 - accuracy: 0.7978 - val_loss: 1.2242 - val_accuracy: 0.4875\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 3s 53ms/step - loss: 0.4456 - accuracy: 0.8006 - val_loss: 1.1153 - val_accuracy: 0.5125\n",
      "Epoch 83/100\n",
      "13/62 [=====>........................] - ETA: 2s - loss: 0.4130 - accuracy: 0.8284"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define image dimensions and number of classes\n",
    "img_width = 60\n",
    "img_height = 64\n",
    "num_classes = 2\n",
    "\n",
    "# Define the CNN architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(img_width,img_height,1)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Create an ImageDataGenerator object to preprocess the data\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "data_dir = r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\Dataset\\Pics_20_5\\Train\"\n",
    "# Create train and validation data generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "data_dir1 = r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\Dataset\\Pics_20_5\\Val\"\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        data_dir1,\n",
    "        target_size=(img_width, img_height),\n",
    "        color_mode='grayscale',\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // 32,\n",
    "        epochs=100,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // 32)\n",
    "\n",
    "# Save the model\n",
    "# model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0003395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 58, 62, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 29, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 27, 29, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 11648)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                745536    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 764,417\n",
      "Trainable params: 764,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "becbf593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.602e+01, 2.324e+01, 1.027e+02, 7.978e+02, 8.206e-02, 6.669e-02,\n",
       "       3.299e-02, 3.323e-02, 1.528e-01, 5.697e-02, 3.795e-01, 1.187e+00,\n",
       "       2.466e+00, 4.051e+01, 4.029e-03, 9.269e-03, 1.101e-02, 7.591e-03,\n",
       "       1.460e-02, 3.042e-03, 1.919e+01, 3.388e+01, 1.238e+02, 1.150e+03,\n",
       "       1.181e-01, 1.551e-01, 1.459e-01, 9.975e-02, 2.948e-01, 8.452e-02])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y= data.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.5,random_state =123)\n",
    "\n",
    "# clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "# models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# print(models)\n",
    "\n",
    "X[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab3d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "IMAGE_WIDTH = {5: 15, 20: 60, 60: 180}\n",
    "IMAGE_HEIGHT = {5: 32, 20: 64, 60: 96}      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2359fdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85644, 64, 60)\n",
      "(85644, 8)\n"
     ]
    }
   ],
   "source": [
    "year_list = np.arange(1993,1994,1)\n",
    "\n",
    "wd = r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\monthly_20d\"\n",
    "\n",
    "images = []\n",
    "label_df = []\n",
    "for year in year_list:\n",
    "    images.append(np.memmap(os.path.join(wd, f\"20d_month_has_vb_[20]_ma_{year}_images.dat\"), dtype=np.uint8, mode='r').reshape(\n",
    "                        (-1, IMAGE_HEIGHT[20], IMAGE_WIDTH[20])))\n",
    "    label_df.append(pd.read_feather(os.path.join(wd, f\"20d_month_has_vb_[20]_ma_{year}_labels_w_delay.feather\")))\n",
    "    \n",
    "images = np.concatenate(images)\n",
    "label_df = pd.concat(label_df)\n",
    "\n",
    "print(images.shape)\n",
    "print(label_df.shape)\n",
    "images = images[:20000]\n",
    "# label_df = label_df.iloc[:20000, :]\n",
    "# X = np.reshape(images, [images.shape[0], 3840])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0558a3ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 64, 60)\n",
      "(20000, 64, 60)\n",
      "(0, 64, 60)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "k = 60000\n",
    "train = images[:k]\n",
    "test = images[k:]\n",
    "# train = tf.expand_dims(train, axis=-1)\n",
    "# test = tf.expand_dims(test, axis = -1)\n",
    "print(train.shape)\n",
    "train = np.reshape(train, [train.shape[0], 3840])\n",
    "print(test.shape)\n",
    "test = np.reshape(test, [test.shape[0], 3840])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4679de64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "label_20 = label_df['Ret_20d']\n",
    "label_20[label_20 > 0] = 1\n",
    "label_20[label_20 <= 0] = 0\n",
    "label_train = label_20[:k]\n",
    "label_test = label_20[k:]\n",
    "label_20 = label_20[:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0bc30531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19879, 3840) (19879,)\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for p, n in zip(images, label_20):\n",
    "    if np.isnan(n):\n",
    "        pass\n",
    "    else:\n",
    "        X.append(p)\n",
    "        y.append(n)\n",
    "        \n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "X = np.reshape(X, [X.shape[0], 3840])\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e2519621",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.isnan(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7925a615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(np.isnan(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7532d464",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|██████████████▏                                                                   | 5/29 [08:13<41:39, 104.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalNB model failed to execute\n",
      "Negative values in data passed to CategoricalNB (input X)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▌        | 26/29 [54:02<11:21, 227.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StackingClassifier model failed to execute\n",
      "__init__() missing 1 required positional argument: 'estimators'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 29/29 [54:48<00:00, 113.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "SVC                                0.53               0.53     0.53      0.53   \n",
      "AdaBoostClassifier                 0.53               0.53     0.53      0.53   \n",
      "NuSVC                              0.53               0.53     0.53      0.53   \n",
      "XGBClassifier                      0.52               0.52     0.52      0.52   \n",
      "RandomForestClassifier             0.52               0.52     0.52      0.52   \n",
      "NearestCentroid                    0.52               0.52     0.52      0.52   \n",
      "ExtraTreesClassifier               0.52               0.52     0.52      0.52   \n",
      "BernoulliNB                        0.52               0.52     0.52      0.52   \n",
      "RidgeClassifierCV                  0.52               0.52     0.52      0.52   \n",
      "LogisticRegression                 0.52               0.52     0.52      0.52   \n",
      "RidgeClassifier                    0.52               0.52     0.52      0.52   \n",
      "LinearDiscriminantAnalysis         0.52               0.52     0.52      0.52   \n",
      "LGBMClassifier                     0.52               0.51     0.51      0.51   \n",
      "ExtraTreeClassifier                0.51               0.51     0.51      0.51   \n",
      "Perceptron                         0.51               0.51     0.51      0.51   \n",
      "DecisionTreeClassifier             0.51               0.51     0.51      0.51   \n",
      "PassiveAggressiveClassifier        0.51               0.51     0.51      0.51   \n",
      "SGDClassifier                      0.51               0.51     0.51      0.51   \n",
      "LinearSVC                          0.51               0.50     0.50      0.51   \n",
      "GaussianNB                         0.50               0.50     0.50      0.49   \n",
      "CalibratedClassifierCV             0.53               0.50     0.50      0.40   \n",
      "KNeighborsClassifier               0.50               0.50     0.50      0.50   \n",
      "BaggingClassifier                  0.50               0.50     0.50      0.49   \n",
      "QuadraticDiscriminantAnalysis      0.51               0.50     0.50      0.48   \n",
      "LabelSpreading                     0.47               0.50     0.50      0.31   \n",
      "LabelPropagation                   0.47               0.50     0.50      0.31   \n",
      "DummyClassifier                    0.53               0.50     0.50      0.36   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "SVC                                595.91  \n",
      "AdaBoostClassifier                  57.92  \n",
      "NuSVC                             1730.05  \n",
      "XGBClassifier                       40.33  \n",
      "RandomForestClassifier              16.81  \n",
      "NearestCentroid                      2.80  \n",
      "ExtraTreesClassifier                24.80  \n",
      "BernoulliNB                          3.28  \n",
      "RidgeClassifierCV                   43.31  \n",
      "LogisticRegression                   7.04  \n",
      "RidgeClassifier                      5.51  \n",
      "LinearDiscriminantAnalysis          42.06  \n",
      "LGBMClassifier                       6.25  \n",
      "ExtraTreeClassifier                  2.85  \n",
      "Perceptron                           4.04  \n",
      "DecisionTreeClassifier              13.28  \n",
      "PassiveAggressiveClassifier          6.13  \n",
      "SGDClassifier                       24.65  \n",
      "LinearSVC                           89.95  \n",
      "GaussianNB                           3.65  \n",
      "CalibratedClassifierCV             345.89  \n",
      "KNeighborsClassifier                 7.39  \n",
      "BaggingClassifier                   84.44  \n",
      "QuadraticDiscriminantAnalysis       77.28  \n",
      "LabelSpreading                      25.17  \n",
      "LabelPropagation                    23.38  \n",
      "DummyClassifier                      2.52  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.3,random_state =123)\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=False, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c83ae6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new = []\n",
    "label_train_new = []\n",
    "\n",
    "for i, j in zip(train, label_train):\n",
    "    if np.isnan(j):\n",
    "        pass\n",
    "    else:\n",
    "        train_new.append(i)\n",
    "        label_train_new.append(j)\n",
    "        \n",
    "test_new = []\n",
    "label_test_new = []\n",
    "\n",
    "for k, m in zip(test, label_test):\n",
    "    if np.isnan(m):\n",
    "        pass\n",
    "    else:\n",
    "        test_new.append(k)\n",
    "        label_test_new.append(m)\n",
    "        \n",
    "train_new = np.array(train_new)\n",
    "test_new = np.array(test_new)\n",
    "label_train_new = np.array(label_train_new)\n",
    "label_test_new = np.array(label_test_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d607674e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 3840)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = r\"C:\\Users\\hayk.darbinyan\\codes\\my_Venvs\\_venv-310-jupyter\\Thesis\\Dataset\\Pics_20_5\\Train\"\n",
    "\n",
    "# Define the target image size\n",
    "target_size = (64, 60)\n",
    "\n",
    "# Load the image data and labels\n",
    "X = []\n",
    "y = []\n",
    "class_names = os.listdir(data_dir)\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    for filename in os.listdir(class_dir):\n",
    "        img = io.imread(os.path.join(class_dir, filename))\n",
    "        img = resize(img, target_size)\n",
    "        X.append(img)\n",
    "        y.append(i)\n",
    "\n",
    "# Convert the data and labels to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape the data into a flat vector for use with the random forest classifier\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "X_train_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59c39561",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 29/29 [00:28<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
      "Model                                                                           \n",
      "LogisticRegression                 0.59               0.59     0.59      0.58   \n",
      "BaggingClassifier                  0.59               0.59     0.59      0.58   \n",
      "LinearSVC                          0.59               0.59     0.59      0.59   \n",
      "QuadraticDiscriminantAnalysis      0.59               0.58     0.58      0.58   \n",
      "PassiveAggressiveClassifier        0.57               0.57     0.57      0.57   \n",
      "BernoulliNB                        0.57               0.57     0.57      0.57   \n",
      "ExtraTreesClassifier               0.56               0.57     0.57      0.51   \n",
      "SGDClassifier                      0.56               0.56     0.56      0.55   \n",
      "RidgeClassifierCV                  0.56               0.56     0.56      0.55   \n",
      "RidgeClassifier                    0.56               0.56     0.56      0.55   \n",
      "NearestCentroid                    0.56               0.56     0.56      0.56   \n",
      "LGBMClassifier                     0.54               0.55     0.55      0.52   \n",
      "AdaBoostClassifier                 0.53               0.53     0.53      0.52   \n",
      "NuSVC                              0.51               0.53     0.53      0.40   \n",
      "Perceptron                         0.51               0.52     0.52      0.51   \n",
      "DecisionTreeClassifier             0.51               0.52     0.52      0.51   \n",
      "CalibratedClassifierCV             0.51               0.52     0.52      0.51   \n",
      "KNeighborsClassifier               0.51               0.51     0.51      0.51   \n",
      "GaussianNB                         0.50               0.51     0.51      0.46   \n",
      "LabelSpreading                     0.51               0.50     0.50      0.35   \n",
      "LabelPropagation                   0.51               0.50     0.50      0.35   \n",
      "DummyClassifier                    0.49               0.50     0.50      0.32   \n",
      "SVC                                0.49               0.50     0.50      0.32   \n",
      "LinearDiscriminantAnalysis         0.49               0.49     0.49      0.43   \n",
      "XGBClassifier                      0.49               0.49     0.49      0.46   \n",
      "RandomForestClassifier             0.46               0.46     0.46      0.42   \n",
      "ExtraTreeClassifier                0.44               0.44     0.44      0.44   \n",
      "\n",
      "                               Time Taken  \n",
      "Model                                      \n",
      "LogisticRegression                   0.29  \n",
      "BaggingClassifier                    3.34  \n",
      "LinearSVC                            0.49  \n",
      "QuadraticDiscriminantAnalysis        0.68  \n",
      "PassiveAggressiveClassifier          0.43  \n",
      "BernoulliNB                          0.30  \n",
      "ExtraTreesClassifier                 1.07  \n",
      "SGDClassifier                        0.24  \n",
      "RidgeClassifierCV                    0.34  \n",
      "RidgeClassifier                      0.32  \n",
      "NearestCentroid                      0.27  \n",
      "LGBMClassifier                       4.51  \n",
      "AdaBoostClassifier                   5.41  \n",
      "NuSVC                                0.79  \n",
      "Perceptron                           0.24  \n",
      "DecisionTreeClassifier               0.83  \n",
      "CalibratedClassifierCV               1.46  \n",
      "KNeighborsClassifier                 0.26  \n",
      "GaussianNB                           0.20  \n",
      "LabelSpreading                       0.20  \n",
      "LabelPropagation                     0.33  \n",
      "DummyClassifier                      0.21  \n",
      "SVC                                  0.68  \n",
      "LinearDiscriminantAnalysis           0.85  \n",
      "XGBClassifier                        2.97  \n",
      "RandomForestClassifier               1.07  \n",
      "ExtraTreeClassifier                  0.30  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train_flat, X_test_flat, y_train, y_test)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08308151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mpl,matplotlib.cm as cm\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import  KMeans\n",
    "n_clusters = 3\n",
    "X,_=datasets.make_blobs(n_samples=10000,n_features=2,centers=3,random_state=0)\n",
    "X = X_train.reshape(270, 3840)\n",
    "clusterer=KMeans(n_clusters).fit(X)\n",
    "colors=cm.nipy_spectral(clusterer.labels_.astype(float)/n_clusters)\n",
    "mpl.scatter(X[:,0],X[:,1],marker='.',s=30,lw=0,alpha=.5,c=colors,edgecolor='k')\n",
    "mpl.savefig('kmeans.png',dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53a5835b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3.71990020e-15, 1.00000000e+00, 3.99680289e-15, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.17647059e-02, 9.84313725e-01, 4.47398110e-15, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [5.88235294e-02, 9.64705882e-01, 3.92156863e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [3.58057810e-15, 9.76470588e-01, 4.43218447e-15, ...,\n",
       "         7.84313725e-03, 3.92156863e-02, 3.13725490e-02],\n",
       "        [3.13725490e-02, 1.00000000e+00, 1.17647059e-02, ...,\n",
       "         3.92156863e-03, 9.17647059e-01, 4.70588235e-02],\n",
       "        [3.77562905e-15, 1.00000000e+00, 2.35294118e-02, ...,\n",
       "         2.78644210e-17, 1.00000000e+00, 3.52941176e-02]],\n",
       "\n",
       "       [[1.00000000e+00, 1.00000000e+00, 4.33117594e-15, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [4.17966315e-17, 1.17647059e-02, 2.35294118e-02, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [1.39322105e-17, 3.92156863e-03, 3.29148473e-16, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [4.70588235e-02, 9.37254902e-01, 1.96078431e-02, ...,\n",
       "         7.80203788e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [3.92156863e-03, 1.00000000e+00, 4.13612499e-15, ...,\n",
       "         5.49019608e-02, 8.74509804e-01, 6.66666667e-02],\n",
       "        [3.58057810e-15, 1.00000000e+00, 1.96078431e-02, ...,\n",
       "         3.92156863e-03, 1.00000000e+00, 3.13725490e-02]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [3.55271368e-15, 1.00000000e+00, 4.13612499e-15, ...,\n",
       "         1.11457684e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [7.45098039e-02, 9.49019608e-01, 7.84313725e-03, ...,\n",
       "         5.09803922e-02, 9.64705882e-01, 9.01960784e-02],\n",
       "        [3.97067999e-15, 9.68627451e-01, 1.96078431e-02, ...,\n",
       "         1.56862745e-02, 9.45098039e-01, 1.40715326e-14]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.17647059e-02, 1.44894989e-15, 1.82149530e-29],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         7.84313725e-03, 9.01960784e-02, 1.28176337e-15],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.52941176e-02, 1.12850905e-15, 5.22457894e-17],\n",
       "        ...,\n",
       "        [7.84313725e-03, 1.00000000e+00, 3.99680289e-15, ...,\n",
       "         7.80203788e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [1.96078431e-02, 9.13725490e-01, 2.74509804e-02, ...,\n",
       "         5.49019608e-02, 8.74509804e-01, 6.66666667e-02],\n",
       "        [3.69203578e-15, 1.00000000e+00, 4.19185384e-15, ...,\n",
       "         3.92156863e-03, 1.00000000e+00, 3.13725490e-02]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.67186526e-16, 1.00000000e+00, 1.43780412e-14],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         4.31898526e-16, 9.60784314e-01, 1.17647059e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.13725490e-02, 9.56862745e-01, 3.13725490e-02],\n",
       "        ...,\n",
       "        [4.17966315e-16, 3.13725490e-02, 1.17647059e-02, ...,\n",
       "         7.80203788e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [3.52941176e-02, 9.64705882e-01, 3.92156863e-03, ...,\n",
       "         5.49019608e-02, 8.74509804e-01, 6.66666667e-02],\n",
       "        [3.80349347e-15, 1.00000000e+00, 7.84313725e-03, ...,\n",
       "         3.92156863e-03, 1.00000000e+00, 3.13725490e-02]],\n",
       "\n",
       "       [[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         2.22915368e-16, 1.00000000e+00, 1.17647059e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         1.56862745e-02, 9.72549020e-01, 1.17647059e-02],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         3.13725490e-02, 9.80392157e-01, 1.00000000e+00],\n",
       "        ...,\n",
       "        [2.35294118e-02, 1.00000000e+00, 3.99680289e-15, ...,\n",
       "         1.11457684e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [3.55271368e-15, 9.52941176e-01, 5.49019608e-02, ...,\n",
       "         1.11457684e-16, 1.00000000e+00, 1.42108547e-14],\n",
       "        [3.92156863e-03, 1.00000000e+00, 4.38690478e-15, ...,\n",
       "         1.11457684e-16, 1.00000000e+00, 1.42108547e-14]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6976049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# class Net(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.layer1 = nn.Sequential(\n",
    "#             nn.Conv2d(1, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "#             nn.BatchNorm2d(64),\n",
    "#             nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#             nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "#         )\n",
    "#         self.layer2 = nn.Sequential(\n",
    "#             nn.Conv2d(64, 128, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "#             nn.BatchNorm2d(128),\n",
    "#             nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#             nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "#         )\n",
    "#         self.layer3 = nn.Sequential(\n",
    "#             nn.Conv2d(128, 256, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "#             nn.BatchNorm2d(256),\n",
    "#             nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "#             nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "#         )\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Dropout(p=0.5),\n",
    "#             nn.Linear(46080, 2),\n",
    "#         )\n",
    "#         self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "#     def forward(self, x):\n",
    "#         x = x.reshape(-1,1,64,60)\n",
    "#         x = self.layer1(x)\n",
    "#         x = self.layer2(x)\n",
    "#         x = self.layer3(x)\n",
    "#         x = x.reshape(-1,46080)\n",
    "#         x = self.fc1(x)\n",
    "#         #x = self.softmax(x)\n",
    "#         return x\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=(5,3), stride=(3,1), dilation=(2,1), padding=(12,1)),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(negative_slope=0.01, inplace=True),\n",
    "            nn.MaxPool2d((2, 1), stride=(2, 1)),\n",
    "        )\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.LazyLinear(46080, 2),\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1,1,64,60)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = x.reshape(-1,46080)\n",
    "        x = self.fc1(x)\n",
    "        #x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96834b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
